{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/anton/PycharmProjects/afishaparser2/afisha_parser/copy_text_db.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classId</th>\n",
       "      <th>raiting</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>222122</td>\n",
       "      <td>1</td>\n",
       "      <td>Феерический бред со спецэфектами.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>222122</td>\n",
       "      <td>1</td>\n",
       "      <td>Не в коем случае не смотреть в кинотеатре))) с...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>222122</td>\n",
       "      <td>5</td>\n",
       "      <td>Офиегнный фильм, один из лучших за послежнее в...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>222122</td>\n",
       "      <td>1</td>\n",
       "      <td>Ужасно. Спали полфильма.... Для галочки сходил...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>222122</td>\n",
       "      <td>1</td>\n",
       "      <td>Тут тома и джери не хватает .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   classId  raiting                                               text\n",
       "0   222122        1                 Феерический бред со спецэфектами. \n",
       "1   222122        1  Не в коем случае не смотреть в кинотеатре))) с...\n",
       "2   222122        5  Офиегнный фильм, один из лучших за послежнее в...\n",
       "3   222122        1  Ужасно. Спали полфильма.... Для галочки сходил...\n",
       "4   222122        1                      Тут тома и джери не хватает ."
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = df\n",
    "df = df[df.raiting != 0]\n",
    "df = df[pd.isnull(df.text) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    13483.000000\n",
       "mean         4.030557\n",
       "std          1.334874\n",
       "min          1.000000\n",
       "25%          3.000000\n",
       "50%          5.000000\n",
       "75%          5.000000\n",
       "max          5.000000\n",
       "Name: raiting, dtype: float64"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.raiting.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    7348\n",
       "4    2704\n",
       "1    1371\n",
       "3    1297\n",
       "2     763\n",
       "Name: raiting, dtype: int64"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.raiting.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    0.544983\n",
       "4    0.200549\n",
       "1    0.101684\n",
       "3    0.096195\n",
       "2    0.056590\n",
       "Name: raiting, dtype: float64"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.raiting.value_counts()/df.raiting.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "TAG_RE = re.compile(r'<[^>]+>')\n",
    "CHARACTER_RE = re.compile(r'[\\r\\n]')\n",
    "\n",
    "def remove_tags(text):\n",
    "    return TAG_RE.sub('', text)\n",
    "\n",
    "def remove_symbols(text):\n",
    "    try:\n",
    "        return re.sub(r'[^а-яА-Яa-zA-Z]+', ' ', text).lower()  \n",
    "    except TypeError as e:\n",
    "        print (text)\n",
    "\n",
    "def stemming(words):\n",
    "    stemmer = SnowballStemmer(\"russian\")\n",
    "    return [stemmer.stem(word) for word in words]\n",
    "\n",
    "def remove_stopwords(words):\n",
    "    rus_stopwords = stopwords.words(\"russian\")\n",
    "    return list(filter(lambda x: x not in rus_stopwords, words)) \n",
    "\n",
    "def preprocessing(text):\n",
    "    return \" \".join(stemming(remove_stopwords(remove_tags(remove_symbols(text)).split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.text = df.text.map(lambda text: preprocessing(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X = df.text\n",
    "y = df.raiting\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from stop_words import get_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "pipeline = Pipeline([\n",
    "           ('vect', TfidfVectorizer(analyzer = \"word\", norm='l2', sublinear_tf=True)),\n",
    "           ('clf', LogisticRegression())\n",
    "       ])\n",
    "parameters = {\n",
    "           'vect__max_df': (0.25, 0.5),\n",
    "           'vect__ngram_range': ((1, 1), (1, 2)),\n",
    "           'vect__use_idf': (True, False),\n",
    "           'clf__C': (0.1, 1, 10),\n",
    "       }\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=3, verbose=1, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:   42.8s\n",
      "[Parallel(n_jobs=3)]: Done  72 out of  72 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "  ...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))]),\n",
       "       fit_params={}, iid=True, n_jobs=3,\n",
       "       param_grid={'vect__ngram_range': ((1, 1), (1, 2)), 'clf__C': (0.1, 1, 10), 'vect__max_df': (0.25, 0.5), 'vect__use_idf': (True, False)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.608989261596\n",
      "{'clf__warm_start': False, 'vect__binary': False, 'clf__fit_intercept': True, 'vect__strip_accents': None, 'vect__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b', 'vect__stop_words': None, 'vect__tokenizer': None, 'clf__n_jobs': 1, 'vect__min_df': 1, 'vect__dtype': <class 'numpy.int64'>, 'clf__max_iter': 100, 'clf__verbose': 0, 'vect__ngram_range': (1, 2), 'vect__sublinear_tf': True, 'clf__C': 10, 'vect__vocabulary': None, 'vect__input': 'content', 'clf__dual': False, 'clf__intercept_scaling': 1, 'vect__use_idf': True, 'clf__tol': 0.0001, 'clf__class_weight': None, 'clf': LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), 'vect__decode_error': 'strict', 'vect__smooth_idf': True, 'vect__analyzer': 'word', 'clf__multi_class': 'ovr', 'clf__random_state': None, 'steps': [('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.5, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)), ('clf', LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))], 'vect__preprocessor': None, 'clf__solver': 'liblinear', 'vect__lowercase': True, 'clf__penalty': 'l2', 'vect__norm': 'l2', 'vect__max_features': None, 'vect__max_df': 0.5, 'vect__encoding': 'utf-8', 'vect': TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.5, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)}\n",
      "\tclf__C: 10\n",
      "\tvect__max_df: 0.5\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__use_idf: True\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_score_)\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "print(best_parameters)\n",
    "for param_name in sorted(parameters.keys()):\n",
    "        print('\\t{0}: {1}'.format(param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.614606741573\n",
      "Confusion Matrix:\n",
      " [[ 239    8   23   42  146]\n",
      " [  66   11   31   40  100]\n",
      " [  31    4   42  142  230]\n",
      " [  13    2   17  211  657]\n",
      " [  22    1    8  132 2232]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.64      0.52      0.58       458\n",
      "          2       0.42      0.04      0.08       248\n",
      "          3       0.35      0.09      0.15       449\n",
      "          4       0.37      0.23      0.29       900\n",
      "          5       0.66      0.93      0.78      2395\n",
      "\n",
      "avg / total       0.56      0.61      0.55      4450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = grid_search.predict(X_test)\n",
    "print('Accuracy:', accuracy_score(y_test, predictions))\n",
    "print('Confusion Matrix:\\n', confusion_matrix(y_test, predictions))\n",
    "print('Classification Report:\\n', classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences = df.text.map(lambda sent: sent.split(\" \")).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_features = 300                    \n",
    "min_word_count = 40                        \n",
    "num_workers = 6\n",
    "context = 10\n",
    "downsampling = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = word2vec.Word2Vec(sentences, workers=num_workers, size=num_features, min_count = min_word_count, window = context, sample = downsampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name = \"300features_40minwords_10context\"\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1889, 300)"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.syn0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#model.index2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.], dtype=float32)"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((num_features,),dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def makeFeatureVec(words, model, num_features):\n",
    "\n",
    "    featureVec = np.zeros((num_features,),dtype=\"float32\")\n",
    "    nwords = 0.\n",
    "    \n",
    "    index2word_set = set(model.index2word)\n",
    "    \n",
    "    for word in words:\n",
    "        if word in index2word_set: \n",
    "            nwords = nwords + 1.\n",
    "            featureVec = np.add(featureVec,model[word])\n",
    "\n",
    "    if nwords != 0:\n",
    "        featureVec = np.divide(featureVec,nwords)\n",
    "    return featureVec\n",
    "\n",
    "\n",
    "def getAvgFeatureVecs(reviews, model, num_features):\n",
    "    counter = 0.\n",
    "    \n",
    "    reviewFeatureVecs = np.zeros((len(reviews),num_features),dtype=\"float32\")\n",
    "    \n",
    "    for review in reviews:\n",
    "        if counter % 1000. == 0.:\n",
    "            print (\"Review {0} of {1}\".format(counter, len(reviews)))\n",
    "       \n",
    "        reviewFeatureVecs[counter] = makeFeatureVec(review, model, num_features)\n",
    "        counter = counter + 1.\n",
    "    return reviewFeatureVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_review = X_train.map(lambda sent: sent.split(\" \")).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_review = X_test.map(lambda sent: sent.split(\" \")).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0.0 of 9033\n",
      "Review 1000.0 of 9033\n",
      "Review 2000.0 of 9033\n",
      "Review 3000.0 of 9033\n",
      "Review 4000.0 of 9033\n",
      "Review 5000.0 of 9033\n",
      "Review 6000.0 of 9033\n",
      "Review 7000.0 of 9033\n",
      "Review 8000.0 of 9033\n",
      "Review 9000.0 of 9033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:27: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "train_data_vec = getAvgFeatureVecs( train_review, model, num_features )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0.0 of 4450\n",
      "Review 1000.0 of 4450\n",
      "Review 2000.0 of 4450\n",
      "Review 3000.0 of 4450\n",
      "Review 4000.0 of 4450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:27: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "test_data_vec = getAvgFeatureVecs( test_review, model, num_features )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "parameters = {\n",
    "           'C': (0.1, 1, 10)\n",
    "       }\n",
    "word2vec_grid_search = GridSearchCV(clf, parameters, n_jobs=3, verbose=1, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58314606741573038"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(C = 1000)\n",
    "clf.fit(train_data_vec, y_train)\n",
    "pred = clf.predict(test_data_vec)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.583146067416\n",
      "Confusion Matrix:\n",
      " [[ 197    1   13   43  204]\n",
      " [  60    0   18   36  134]\n",
      " [  36    1   28   75  309]\n",
      " [  27    0   14  106  753]\n",
      " [  42    0   14   75 2264]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.43      0.48       458\n",
      "          2       0.00      0.00      0.00       248\n",
      "          3       0.32      0.06      0.10       449\n",
      "          4       0.32      0.12      0.17       900\n",
      "          5       0.62      0.95      0.75      2395\n",
      "\n",
      "avg / total       0.49      0.58      0.50      4450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_result(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.583146067416\n",
      "Confusion Matrix:\n",
      " [[ 197    1   13   43  204]\n",
      " [  60    0   18   36  134]\n",
      " [  36    1   28   75  309]\n",
      " [  27    0   14  106  753]\n",
      " [  42    0   14   75 2264]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.43      0.48       458\n",
      "          2       0.00      0.00      0.00       248\n",
      "          3       0.32      0.06      0.10       449\n",
      "          4       0.32      0.12      0.17       900\n",
      "          5       0.62      0.95      0.75      2395\n",
      "\n",
      "avg / total       0.49      0.58      0.50      4450\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def print_result(y_test, predictions):\n",
    "    print('Accuracy:', accuracy_score(y_test, predictions))\n",
    "    print('Confusion Matrix:\\n', confusion_matrix(y_test, predictions))\n",
    "    print('Classification Report:\\n', classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
